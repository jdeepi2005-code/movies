{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaiJntANL8ig",
        "outputId": "29904f2a-a383-4060-a1cd-e28fe185f528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for 'The Dark Knight Rises':\n",
            "The Dark Knight\n",
            "Batman Returns\n",
            "Batman Begins\n",
            "Batman Forever\n",
            "Batman\n",
            "Batman\n",
            "Batman: The Dark Knight Returns, Part 2\n",
            "Batman & Robin\n",
            "Batman v Superman: Dawn of Justice\n",
            "Slow Burn\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def load_and_preprocess_data(movies_path, credits_path):\n",
        "    # Load datasets\n",
        "    credits = pd.read_csv(credits_path)\n",
        "    movies = pd.read_csv(movies_path)\n",
        "\n",
        "    # Merge datasets on title\n",
        "    movies = movies.merge(credits, on='title')\n",
        "\n",
        "    # Select relevant columns\n",
        "    movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "    # Drop rows with missing values\n",
        "    movies.dropna(inplace=True)\n",
        "\n",
        "    # Helper function to extract names from JSON-like strings\n",
        "    def convert(obj):\n",
        "        L = []\n",
        "        for i in ast.literal_eval(obj):\n",
        "            L.append(i['name'])\n",
        "        return L\n",
        "\n",
        "    # Process genres and keywords\n",
        "    movies['genres'] = movies['genres'].apply(convert)\n",
        "    movies['keywords'] = movies['keywords'].apply(convert)\n",
        "\n",
        "    # Process cast: Only keep the top 3 actors\n",
        "    movies['cast'] = movies['cast'].apply(lambda x: [i['name'] for i in ast.literal_eval(x)[:3]])\n",
        "\n",
        "    # Process crew: Only keep the Director\n",
        "    def fetch_director(obj):\n",
        "        L = []\n",
        "        for i in ast.literal_eval(obj):\n",
        "            if i['job'] == 'Director':\n",
        "                L.append(i['name'])\n",
        "                break\n",
        "        return L\n",
        "\n",
        "    movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "\n",
        "    # Combine all metadata into a single 'tags' column\n",
        "    # Also clean overview (split into list)\n",
        "    movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
        "\n",
        "    # Remove spaces from names to avoid confusion (e.g., \"Johnny Depp\" -> \"JohnnyDepp\")\n",
        "    movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
        "    movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
        "    movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
        "    movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
        "\n",
        "    movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
        "\n",
        "    # Convert tags list back to a string and lowercase it\n",
        "    new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
        "    new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x).lower())\n",
        "\n",
        "    return new_df\n",
        "\n",
        "def build_model(df):\n",
        "    # Vectorize the tags using TF-IDF\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(df['tags'])\n",
        "\n",
        "    # Calculate Cosine Similarity\n",
        "    similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def get_recommendations(movie_title, df, similarity):\n",
        "    try:\n",
        "        # Get index of the movie\n",
        "        idx = df[df['title'] == movie_title].index[0]\n",
        "\n",
        "        # Get similarity scores\n",
        "        distances = similarity[idx]\n",
        "\n",
        "        # Sort and pick top 10 (excluding itself)\n",
        "        movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:11]\n",
        "\n",
        "        print(f\"Recommendations for '{movie_title}':\")\n",
        "        for i in movies_list:\n",
        "            print(df.iloc[i[0]].title)\n",
        "\n",
        "    except IndexError:\n",
        "        print(\"Movie not found in dataset.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Preprocess\n",
        "    movies_df = load_and_preprocess_data('/content/drive/MyDrive/Colab Notebooks/new/tmdb_5000_movies.csv', '/content/drive/MyDrive/Colab Notebooks/new/tmdb_5000_credits.csv')\n",
        "\n",
        "    # 2. Build similarity matrix\n",
        "    similarity_matrix = build_model(movies_df)\n",
        "\n",
        "    # 3. Test recommendation\n",
        "    get_recommendations('The Dark Knight Rises', movies_df, similarity_matrix)\n",
        "\n",
        "    # 4. Save the model and data for future use (Deployment)\n",
        "    with open('movie_list.pkl', 'wb') as f:\n",
        "        pickle.dump(movies_df, f)\n",
        "    with open('similarity.pkl', 'wb') as f:\n",
        "        pickle.dump(similarity_matrix, f)"
      ]
    }
  ]
}